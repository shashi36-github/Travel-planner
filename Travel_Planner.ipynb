{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shashi36-github/Travel-planner/blob/main/Travel_Planner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TRAVEL PLANNER\n"
      ],
      "metadata": {
        "id": "lZMwPaKaXM9H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EuP4dJ73b8H9",
        "outputId": "980730dd-80c7-4fe5-98ac-b644f30a028f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rake-nltk\n",
            "  Downloading rake_nltk-1.0.6-py3-none-any.whl (9.1 kB)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.6.2 in /usr/local/lib/python3.10/dist-packages (from rake-nltk) (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.6.2->rake-nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.6.2->rake-nltk) (1.4.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.6.2->rake-nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.6.2->rake-nltk) (4.66.2)\n",
            "Installing collected packages: rake-nltk\n",
            "Successfully installed rake-nltk-1.0.6\n"
          ]
        }
      ],
      "source": [
        "pip install rake-nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "import nltk\n",
        "from rake_nltk import Rake\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "# Load the dataset\n",
        "dataset = pd.read_csv(\"/content/travel_cities_dataset_updated.csv\")\n",
        "\n",
        "def preprocess_text(sentence):\n",
        "    tokens = word_tokenize(sentence.lower())\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "    return set(lemmatized_tokens)\n",
        "\n",
        "# Function to extract keywords using RAKE and match with attributes\n",
        "def extract_keywords(sentence, attributes, n_keywords=5):\n",
        "    rake = Rake()\n",
        "    rake.extract_keywords_from_text(sentence)\n",
        "    keywords = rake.get_ranked_phrases()[:n_keywords]\n",
        "    preprocessed_keywords = preprocess_text(' '.join(keywords))\n",
        "    matched_attributes = set()\n",
        "    for keyword in preprocessed_keywords:\n",
        "        for attribute in attributes:\n",
        "            if keyword in attribute.lower():\n",
        "                matched_attributes.add(attribute)\n",
        "            else:\n",
        "                for syn in wordnet.synsets(keyword):\n",
        "                    for lemma in syn.lemmas():\n",
        "                        if lemma.name() in attribute.lower():\n",
        "                            matched_attributes.add(attribute)\n",
        "                            break\n",
        "    return matched_attributes\n",
        "\n",
        "# Function to suggest destinations\n",
        "def suggest_destinations(matched_attributes):\n",
        "    matched_destinations = []\n",
        "    for index, row in dataset.iterrows():\n",
        "        destination_attributes = set(row['Attributes'].split(','))\n",
        "        score = len(matched_attributes.intersection(destination_attributes))\n",
        "        if score > 0:\n",
        "            matched_destinations.append((row['Destination'], destination_attributes, score))\n",
        "    matched_destinations.sort(key=lambda x: (x[2], x[2]), reverse=True)\n",
        "    return matched_destinations[:3]\n",
        "\n",
        "# Function to analyze sentiment\n",
        "def analyze_sentiment(feedback):\n",
        "    sia = SentimentIntensityAnalyzer()\n",
        "    sentiment_score = sia.polarity_scores(feedback)['compound']\n",
        "    return sentiment_score\n",
        "\n",
        "# Function to update attribute scores based on user feedback\n",
        "def update_attribute_scores(destination, attribute_index, sentiment_score):\n",
        "\n",
        "    index = dataset.index[dataset['Destination'] == destination].tolist()\n",
        "    if not index:\n",
        "        print(f\"Destination '{destination}' not found in the dataset.\")\n",
        "        return\n",
        "\n",
        "    index = index[0]\n",
        "\n",
        "\n",
        "    attribute_score_column = f\"Attribute{attribute_index}_Score\"\n",
        "\n",
        "    print(f\"Updating attribute score for {destination}, attribute {attribute_index}, sentiment score {sentiment_score}\")\n",
        "\n",
        "\n",
        "    current_score = dataset.at[index, attribute_score_column]\n",
        "\n",
        "    # Update the score based on user feedback\n",
        "    updated_score = float(current_score) + 0.3 * sentiment_score\n",
        "\n",
        "    print(f\"Current score: {current_score}, Updated score: {updated_score}\")\n",
        "\n",
        "\n",
        "    dataset.at[index, attribute_score_column] = str(updated_score)\n",
        "\n",
        "\n",
        "    dataset.to_csv(\"travel_cities_dataset_updated.csv\", index=False)\n",
        "\n",
        "\n",
        "def main():\n",
        "    attributes = dataset['Attributes'].str.split(',').explode().str.strip().unique()\n",
        "\n",
        "    print(\"Welcome to the Travel Destination Recommender!\")\n",
        "    print(\"Please provide some information about your travel preferences.\")\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"Your input: \")\n",
        "\n",
        "\n",
        "        matched_attributes = extract_keywords(user_input, attributes)\n",
        "\n",
        "\n",
        "        recommendations = suggest_destinations(matched_attributes)\n",
        "\n",
        "        if recommendations:\n",
        "            print(\"Based on your input, here are some travel destinations:\")\n",
        "            for i, (destination, destination_attributes, score) in enumerate(recommendations, 1):\n",
        "                print(f\"{i}. Destination: {destination}, Attributes: {', '.join(destination_attributes)} (Match Score: {score})\")\n",
        "        else:\n",
        "            print(\"Sorry, I couldn't find any suitable travel destinations based on your input.\")\n",
        "\n",
        "\n",
        "        feedback = input(\"Do any of these recommendations suit your taste? \")\n",
        "\n",
        "\n",
        "        sentiment_score = analyze_sentiment(feedback)\n",
        "\n",
        "        # Update attribute scores based on user feedback\n",
        "        if sentiment_score > 0:\n",
        "            destination_index = int(input(\"Enter the index of the destination you liked (1, 2, 3): \")) - 1\n",
        "            destination, destination_attributes, _ = recommendations[destination_index]\n",
        "            print(f\"Attributes of {destination}:\")\n",
        "            for i, attr in enumerate(destination_attributes, 1):\n",
        "                print(f\"{i}. {attr}\")\n",
        "            selected_attribute_index = int(input(\"Enter the index of the attribute you liked: \")) - 1\n",
        "            update_attribute_scores(destination, selected_attribute_index + 1, sentiment_score)\n",
        "        elif sentiment_score < 0:\n",
        "            print(\"Which destination you didn't like?\")\n",
        "            destination_index = int(input()) - 1\n",
        "            destination, destination_attributes, _ = recommendations[destination_index]\n",
        "            print(f\"Here are the attributes of the destination {destination}:\")\n",
        "            for i, attr in enumerate(destination_attributes, 1):\n",
        "                print(f\"{i}. {attr}\")\n",
        "            attribute_index = int(input(\"Enter the index of the attribute you didn't like: \")) - 1\n",
        "            update_attribute_scores(destination, attribute_index + 1, sentiment_score)\n",
        "        else:\n",
        "            print(\"No sentiment detected.\")\n",
        "\n",
        "        # Ask if the user wants to continue or stop\n",
        "        choice = input(\"Would you like to continue exploring travel destinations? (yes/no) \").lower()\n",
        "        if choice == \"no\":\n",
        "            print(\"Thank you for using the Travel Destination Recommender. Have a great day!\")\n",
        "            break\n",
        "        elif choice != \"yes\":\n",
        "            print(\"Sorry, I didn't understand your response. Let's continue exploring.\")\n",
        "            continue\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1txPy0YQb-bz",
        "outputId": "84583fc2-6bab-46a9-ee97-69363cdb60b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to the Travel Destination Recommender!\n",
            "Please provide some information about your travel preferences.\n",
            "Your input: I want to go for boating\n",
            "Based on your input, here are some travel destinations:\n",
            "1. Destination: Surat, Attributes: boating, sports, gardens, museums (Match Score: 1)\n",
            "2. Destination: Nashik, Attributes: beaches, boating, handicrafts (Match Score: 1)\n",
            "3. Destination: Srinagar, Attributes: cycling, wildlife, dance performances, boating (Match Score: 1)\n",
            "Do any of these recommendations suit your taste? yes they do\n",
            "Enter the index of the destination you liked (1, 2, 3): 3\n",
            "Attributes of Srinagar:\n",
            "1. cycling\n",
            "2. wildlife\n",
            "3. dance performances\n",
            "4. boating\n",
            "Enter the index of the attribute you liked: 2\n",
            "Updating attribute score for Srinagar, attribute 2, sentiment score 0.4019\n",
            "Current score: 1, Updated score: 1.12057\n",
            "Would you like to continue exploring travel destinations? (yes/no) no\n",
            "Thank you for using the Travel Destination Recommender. Have a great day!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attributes = dataset['Attributes'].str.split(',').explode().str.strip().unique()\n",
        "\n",
        "# Test cases\n",
        "test_cases = [\n",
        "    {\"input\": \"historical landmarks\", \"expected_keywords\": {\"historical landmarks\"}},\n",
        "    {\"input\": \"vibrant nightlife\", \"expected_keywords\": {\"nightlife\"}},\n",
        "    {\"input\": \"cultural festivals \", \"expected_keywords\": {\"cultural festivals\"}},\n",
        "    {\"input\": \"beautiful beaches\", \"expected_keywords\": {\"beaches\"}},\n",
        "    {\"input\": \"handicrafts\", \"expected_keywords\": {\"handicrafts\"}},\n",
        "    {\"input\": \"nature photography\", \"expected_keywords\": {\"photography\"}},\n",
        "    {\"input\": \"hiking \", \"expected_keywords\": {\"hiking\"}},\n",
        "    {\"input\": \"boating \", \"expected_keywords\": {\"boating\"}},\n",
        "    {\"input\": \"beautiful scenery\", \"expected_keywords\": {\"scenery\"}},\n",
        "    {\"input\": \"vibrant nightlife\", \"expected_keywords\": {\"nightlife\"}},\n",
        "    {\"input\": \"souvenirs \", \"expected_keywords\": {\"souvenirs\"}},\n",
        "    {\"input\": \"snorkeling\", \"expected_keywords\": {\"snorkeling\"}},\n",
        "    {\"input\": \"wildlife\", \"expected_keywords\": {\"wildlife\"}},\n",
        "]\n",
        "\n",
        "# Count of correct extractions\n",
        "correct_extractions = 0\n",
        "\n",
        "# Iterate through keyword test cases\n",
        "for case in test_cases:\n",
        "    input_sentence = case[\"input\"]\n",
        "    expected_keywords = case[\"expected_keywords\"]\n",
        "\n",
        "    # Extract keywords from input sentence\n",
        "    extracted_keywords = extract_keywords(input_sentence, attributes)\n",
        "\n",
        "    # Check if the extracted keywords match the expected keywords\n",
        "    if extracted_keywords == expected_keywords:\n",
        "        correct_extractions += 1\n",
        "\n",
        "# Calculate accuracy\n",
        "total_keyword_test_cases = len(test_cases)\n",
        "accuracy = (correct_extractions / total_keyword_test_cases) * 100\n",
        "\n",
        "print(f\"Keyword Extraction Accuracy: {accuracy:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3ZuYIpJb-xr",
        "outputId": "e4fd57dd-1d09-4742-aef2-e6fbffd8f587"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyword Extraction Accuracy: 92.31%\n"
          ]
        }
      ]
    }
  ]
}